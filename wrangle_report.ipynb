{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: \"WeRateDoge\" Data Wrngling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is wrangle \"WeRateDogs\". The main followed steps to wrangle them are the following: \n",
    "<br>**1. Gather Data\n",
    "<br>2. Assess\n",
    "<br>3. Clean**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gather Twitter Data Information:\n",
    "There are three resources the data were gathered from:\n",
    "1. Given `twitter-archive-enhanced.csv` file\n",
    "  - This file provides lots of information about each tweet, as its text, the related tweeting time, the dog rating and the stage. This file will be read from the current working directory\n",
    "2. The retweets and favorite counts of each tweet are not in  `twitter-archive-enhanced.csv` file. Therefore we will use the given tweet_id in the file to retrieve the counts using Twitter API\n",
    "3. Additionally a hosted `image-predictions.tsv` file give us the top three breeds predictions of each dog image for the related tweets. This file is downloaded programtically from the given URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Assess Datasets\n",
    "\n",
    "We will need to see datasets samples, preview theier information and descriptions to provide our assessment\n",
    "#### Quality\n",
    "Content Issues: Completeness, Validity, Accuracy, Consistency\n",
    "<br>\n",
    "**`archive_df` Table**: The dataframe of `twitter-archive-enhanced.csv` file\n",
    "1. Remove retweets rows and keep original tweets only\n",
    "2. Drop `retweeted_status_id`, `retweeted_status_user_id` and `retweeted_status_timestamp` columns as they contian only None for the original tweets\n",
    "3. Change `tweet_id` from int64 to object\n",
    "4. Change `timestamp` type from object to datetime\n",
    "5. Remove  `in_reply_to_status_id` and `in_reply_to_user_id` columns as they present only non null values in 3.3% of the entire dataset and will not help in any future analysis\n",
    "6. Correct the wrong values in `rating_denominator` and `rating_numerator` columns\n",
    "7. Change the datatypes for `rating_denominator` and `rating_numerator` to floats. As the correct ratings contain float values\n",
    "8. Replace the lowercase names with \"UNKNOWN\" as they are for stopwords not the correct names\n",
    "\n",
    "**`image_df` Table**: The dataframe of `image-predictions.tsv`\n",
    "9. Change `tweet_id` from int64 to object\n",
    "10. Correct the names capitalization in `p1`, `p2` and `p3` by converting them all to lowercase\n",
    "\n",
    "**`tweets_json_df` Table**: The resulted dataframe of gathering tweets infromation from Twitter and keeping only the important information\n",
    "11. Remove extra columns by keeping only `id`, `retweet_count` and `favorite_count` \n",
    "12. Rename the `id` column to `tweet_id` to be consistent with the other tables `tweet_id` column\n",
    "13. Change `tweet_id` from int64 to object\n",
    "\n",
    "#### Tidiness\n",
    "Each variable forms a column. Each observation forms a row. Each type of observational unit forms a table.\n",
    "\n",
    "1. Join the three tables using the unique column value `tweet_id`\n",
    "2. Melt the four dogs stages `doggo`, `floofer`, `pupper` and `puppo` columns into `stage` column and drop the four columns from `archive_df` table\n",
    "3. Add `rating` column resulted from dividing the correct `rating_numerator` on the correct `rating_denominator`, and remove these two columns \n",
    "\n",
    "\n",
    "* Changing Tweet_id in the three tables will be done after merging the three tables to reduce redunduncy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean\n",
    "\n",
    "All the steps mentioned in the ASSESSMENT were passed through in CLEANING, by defining each step, executing it using one of the found methods found on stackoverflow or github, aand then tested by previewing the dataframe info, describtion or the related column value_counts.<br>\n",
    "After finishing the cleaning process, some statisics were visualized to see thier common values and the relations between the different varibles in the resulted clean dataframe."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
